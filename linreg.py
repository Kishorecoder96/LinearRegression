# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1plj-R27Um0X3VT4nmwYAgZdcGA6dW4J1
"""

import numpy as np

class Linear_Regression():
  def __init__(self,learning_rate,no_of_iterations):
    self.learning_rate=learning_rate
    self.no_of_iterations=no_of_iterations

    # fit function to the training model
  def fit(self,x,y):
    #no_of training examples and no of features
    self.m,self.n=x.shape
    #initiating the weights and bias
    self.w=np.zeros(self.n)
    self.b=0
    self.x=x
    self.y=y


    #implementing the gradient descent for optimization
    for  i in range(self.no_of_iterations):
      self.update_weights()

    #function to update weights in gradient descent
  def update_weights(self):
    y_prediction=self.predict(self.x)

      #calculate gradients

    dw=-(2*(self.x.T).dot(self.y-y_prediction))/self.m
    db=-2*np.sum(self.y-y_prediction)/self.m


      #updating the weights


    self.w=self.w-self.learning_rate*dw
    self.b=self.b-self.learning_rate*db

  def predict(self,X):
    return X.dot(self.w)+self.b

import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

df=pd.read_csv("/content/salary_data (1).csv")

X=df.loc[:,"YearsExperience"].values
Y=df.loc[:,"Salary"].values
X = X.reshape(-1, 1)

print(X)

print(Y)

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33,random_state=2)

model=Linear_Regression(learning_rate=0.02,no_of_iterations=1000)

model.fit(X_train,Y_train)

print("weight=",model.w[0])
print("bias=",model.b)

test_data_prediction=model.predict(X_test)



plt.scatter(X_test, Y_test, color = 'red')
plt.plot(X_test, test_data_prediction, color='blue')
plt.xlabel(' Work Experience')
plt.ylabel('Salary')
plt.title(' Salary vs Experience')
plt.show()

